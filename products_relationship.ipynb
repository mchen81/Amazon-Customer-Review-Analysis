{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col \n",
    "metadata = spark.read.json(\"/amazon-meta/parsed_metadata\")\n",
    "\n",
    "#meta_rdd_dict = metadata.select('product_id', 'title').rdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def parse_line(line):\n",
    "    infos = line.split('\\t')\n",
    "    # date, products\n",
    "    return (infos[0] + infos[1], infos[2])\n",
    "\n",
    "def distinct_products(products):\n",
    "    products_list = set(products)\n",
    "    distinct = []\n",
    "    for p in products:\n",
    "        distinct.append((p, 1))\n",
    "    return distinct\n",
    "\n",
    "def combine_products(products): # [products]\n",
    "    products_list = list(set(products))\n",
    "    products_list.sort()\n",
    "    return combinations(products_list, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = sc.textFile('/amazon-reviews/parsed_data/') \\\n",
    "    .map(lambda line: parse_line(line)).groupByKey()\n",
    "\n",
    "two_products_occ = grouped_data\\\n",
    "    .flatMap(lambda row: combine_products(row[1]))\\\n",
    "    .map(lambda comb: (comb, 1))\\\n",
    "    .reduceByKey(lambda a, b: a + b)\\\n",
    "    .map(lambda reduced: (reduced[0][0], reduced[0][1], reduced[1]))\\\n",
    "    .filter(lambda row: row[2] > 10) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_count = grouped_data\\\n",
    "    .flatMap(lambda row: distinct_products(row[1]))\\\n",
    "    .reduceByKey(lambda a, b: a + b)\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_count = sc.broadcast(products_count.collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B000JXN21W', 'B000JXOSYC', 100.0),\n",
       " ('B000006A93', 'B0026P9Q0W', 100.0),\n",
       " ('B000065UKU', 'B001NS5IIW', 100.0),\n",
       " ('0692365877', 'B00RYPV9PE', 100.0),\n",
       " ('B00GYHBZP2', 'B00GYHC04W', 100.0),\n",
       " ('0752894226', 'B003TO5AJK', 100.0),\n",
       " ('B000002564', 'B000008KG0', 100.0),\n",
       " ('0940232766', 'B0006QZITQ', 100.0),\n",
       " ('B009F3PUP8', 'B014RL77M6', 100.0),\n",
       " ('1512310565', 'B00YDWQFYQ', 100.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_relationship(row):\n",
    "    p1 = row[0]\n",
    "    p2 = row[1]\n",
    "    occurrence = row[2]\n",
    "    products_count_dict = products_count.value\n",
    "    p12_sum = products_count_dict[p1] + products_count_dict[p2]\n",
    "    relevance = (occurrence / (p12_sum - occurrence)) * 100\n",
    "    return (p1, p2, relevance)\n",
    "\n",
    "products_relevance = two_products_occ \\\n",
    "    .map(lambda row: cal_relationship(row)) \\\n",
    "    .sortBy(lambda row: -row[2]) \\\n",
    "\n",
    "products_relevance.take(10)\n",
    "\n",
    "    #.map(lambda row: get_product_info(row[0], metadata) + '\\t' + get_product_info(row[1], metadata)  + '\\t' + \"{:.2f}\".format(row[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B000JXN21W', 'B000JXOSYC', 100.0),\n",
       " ('B000006A93', 'B0026P9Q0W', 100.0),\n",
       " ('B000065UKU', 'B001NS5IIW', 100.0),\n",
       " ('0692365877', 'B00RYPV9PE', 100.0),\n",
       " ('B00GYHBZP2', 'B00GYHC04W', 100.0),\n",
       " ('0752894226', 'B003TO5AJK', 100.0),\n",
       " ('B000002564', 'B000008KG0', 100.0),\n",
       " ('0940232766', 'B0006QZITQ', 100.0),\n",
       " ('B009F3PUP8', 'B014RL77M6', 100.0),\n",
       " ('1512310565', 'B00YDWQFYQ', 100.0),\n",
       " ('B001C04WA6', 'B001C06RPO', 100.0),\n",
       " ('B001E5CJIG', 'B001E762R8', 100.0),\n",
       " ('B001BLTHBA', 'B001BLUZ4S', 100.0),\n",
       " ('0062079670', 'B00IRC8CD0', 100.0),\n",
       " ('1502971429', 'B00OW9RSPK', 100.0),\n",
       " ('B000002GB6', 'B000002GB7', 100.0),\n",
       " ('B001F7D0OA', 'B001F7FAUC', 100.0),\n",
       " ('B0091JK4KC', 'B00DVQ7DRS', 100.0),\n",
       " ('6303391915', 'B00009NH9Z', 100.0),\n",
       " ('0595240577', 'B004I6EKJ4', 100.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_relevance.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_relevance.saveAsTextFile('/amazon-reviews-analysis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_relevance.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_product_info(product_id):\n",
    "    row = meta.select('title').where(col('product_id') == product_id).rdd.collect()\n",
    "    if len(row) == 0:\n",
    "        return ''\n",
    "    return row[0]['title']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most hot products of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- brand: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the metadata at first\n",
    "metaDF = spark.read.json(\"hdfs://orion11:21001/parsed-meta/\")\n",
    "\n",
    "metaDF.createOrReplaceTempView(\"viewMetaData\")\n",
    "\n",
    "metaDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+------------------+\n",
      "|               title|      asin|count|     average_score|\n",
      "+--------------------+----------+-----+------------------+\n",
      "|Powerstep Pinnacl...|B000V0IBDM| 4279| 4.515073615330684|\n",
      "|Powerstep Pinnacl...|B000KPIHQ4| 4270| 4.517330210772834|\n",
      "|90 Degree By Refl...|B00I0VHS10| 3608| 4.428215077605321|\n",
      "|MJ Metals Jewelry...|B00RLSCLJM| 3577| 4.826670394185071|\n",
      "|Hanes Mens EcoSma...|B000YFSR5G| 2420|  3.81198347107438|\n",
      "|i play. Baby Boys...|B000PHANNM| 2401| 4.658892128279883|\n",
      "| i play. Baby Sol...|B00201ER88| 2081| 4.423354156655454|\n",
      "|Best RFID Blockin...|B00GXE331K| 1873| 4.225840896956754|\n",
      "|i play. Girls' Ba...|B000P0X15G| 1823| 4.415249588590236|\n",
      "|Marino Avenue Men...|B00XT15P8E| 1790| 4.732960893854749|\n",
      "|Totes Kids Bubble...|B0017U1KBK| 1710| 4.194152046783626|\n",
      "|Ingrid &amp; Isab...|B005N7YWX6| 1640|4.3012195121951216|\n",
      "|Hanes Mens EcoSma...|B000YFSR4W| 1566|3.8371647509578546|\n",
      "|BodyJ4You Lot of ...|B004HX6P1E| 1544|4.3270725388601035|\n",
      "|Vans Adult Classi...|B000JOOR7O| 1535| 4.409120521172638|\n",
      "|Scarleton Large S...|B009RUKQ2G| 1500| 4.198666666666667|\n",
      "|LaSuiveur Womens ...|B00ZW3SCF0| 1490|3.9885906040268457|\n",
      "|Carhartt Men's Lo...|B000GHMRLW| 1370| 4.313868613138686|\n",
      "|Carhartt Men's Lo...|B000GHRZN2| 1370| 4.313868613138686|\n",
      "|O'Neill Men's Son...|B00NIVAEG8| 1334| 4.272863568215892|\n",
      "+--------------------+----------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1: AMAZON_FASHION\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/AMAZON_FASHION.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count , AVG(overall) as average_score FROM AMAZON_FASHION WHERE verified = True GROUP BY asin ORDER BY count DESC LIMIT 20\")\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"sqlDF1\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF1 LEFT JOIN viewMetaData ON sqlDF1.asin = viewMetadata.product_id ORDER BY count DESC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|      asin|count|     average_score|\n",
      "+----------+-----+------------------+\n",
      "|B000FOI48G| 7711| 4.446894047464661|\n",
      "|B000GLRREU| 7476| 4.448234349919743|\n",
      "|1620213982| 4532|4.7950132391879965|\n",
      "|B001QY8QXM| 4270|4.5688524590163935|\n",
      "|B01DKQAXC0| 4090| 4.217848410757946|\n",
      "|B006IB5T4W| 2260| 4.664159292035398|\n",
      "|B00005JS5C| 2154| 4.088672237697307|\n",
      "|B000WYJTZG| 2091|3.9775227164036346|\n",
      "|B00W259T7G| 1987| 4.498238550578762|\n",
      "|B0012Y0ZG2| 1910| 4.843455497382199|\n",
      "|B00VF344X0| 1875|4.3802666666666665|\n",
      "|B00BMVV3MK| 1702| 4.503525264394829|\n",
      "|B0067F28ZW| 1644|3.8899026763990268|\n",
      "|B000050FDY| 1417| 4.658433309809457|\n",
      "|B000FED5DU| 1128| 4.284574468085107|\n",
      "|B008U1Q4DI| 1128|  4.37145390070922|\n",
      "|B001AJ6YS2| 1037| 4.215043394406943|\n",
      "|B00D3M0CRS| 1034| 4.608317214700193|\n",
      "|B00G5L867C| 1001| 4.653346653346653|\n",
      "|B0013NB7DW|  974| 4.431211498973306|\n",
      "+----------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2: All_Beauty\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/All_Beauty.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count , AVG(overall) as average_score FROM AMAZON_FASHION WHERE verified = True GROUP BY asin ORDER BY count DESC LIMIT 20\")\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"sqlDF1\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF1 LEFT JOIN viewMetaData ON sqlDF1.asin = viewMetadata.product_id ORDER BY count DESC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|      asin|count|     average_score|\n",
      "+----------+-----+------------------+\n",
      "|B00MQSMDYU|12908| 4.570808800743725|\n",
      "|B005NF5NTK|12731| 4.386615348362265|\n",
      "|B00X5RV14Y|11675|4.6199571734475375|\n",
      "|B014EB532U|10327| 4.214098963881089|\n",
      "|B00QN1T6NM|10072| 4.060961080222398|\n",
      "|B00AANQLRI| 9808| 4.590232463295269|\n",
      "|B00MXWFUQC| 9474|3.6809161916824995|\n",
      "|B00G7UY3EG| 8716|3.5486461679669574|\n",
      "|B00VH88CJ0| 8542|4.6362678529618355|\n",
      "|B00BT8L2MW| 8397| 4.486602357984995|\n",
      "|B018JW3EOY| 8338| 4.502878388102663|\n",
      "|B00P7N0320| 8276| 4.506645722571291|\n",
      "|B0092KJ9BU| 8002| 4.001499625093727|\n",
      "|B0194WDVHI| 7821| 4.628947704897072|\n",
      "|B00JH88NHI| 7495| 4.472848565710474|\n",
      "|B00NCJ4GP6| 7460|3.5180965147453085|\n",
      "|B00D856NOG| 7449|   4.7058665592697|\n",
      "|B0085JRQZU| 6928|4.2485565819861435|\n",
      "|B01CDVZAH6| 6845|3.5716581446311175|\n",
      "|B005SUHRVC| 6791|3.8930938006184657|\n",
      "+----------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3: Cell_Phones_and_Accessories\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Cell_Phones_and_Accessories.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count , AVG(overall) as average_score FROM AMAZON_FASHION WHERE verified = True GROUP BY asin ORDER BY count DESC LIMIT 20\")\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"sqlDF1\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF1 LEFT JOIN viewMetaData ON sqlDF1.asin = viewMetadata.product_id ORDER BY count DESC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|      asin|count|     average_score|\n",
      "+----------+-----+------------------+\n",
      "|B010OYASRG|27319|4.4092389911783005|\n",
      "|B00L0YLRUW|19651|3.9666174749376624|\n",
      "|B00DIF2BO2|16242| 4.429380618150474|\n",
      "|B003L1ZYYW|15455| 4.722937560659981|\n",
      "|B0019HL8Q8|14868| 4.735203120796341|\n",
      "|B00IVPU7AO|13795| 4.170714026821312|\n",
      "|B00BWF5U0M|13677|  4.37515537032975|\n",
      "|B0019EHU8G|13666| 4.724937801843993|\n",
      "|B00ITIQI92|13535|4.6105652013298855|\n",
      "|B000BQ7GW8|12906| 4.570122423678909|\n",
      "|B006GWO5WK|12889|  4.32399720692063|\n",
      "|B0015DYMVO|12792| 4.209818636647905|\n",
      "|B00M55C0NS|12152| 4.633887425938117|\n",
      "|B0043T7FXE|12101| 4.472440294190562|\n",
      "|B00E055H5O|11440| 4.500874125874126|\n",
      "|B00BP5KOPA|10383| 4.110661658480208|\n",
      "|B0043WJRRS|10345| 4.808989850169164|\n",
      "|B000VS4HDM|10245|4.5627135187896535|\n",
      "|B006W8U2MU| 9857| 4.560109566805316|\n",
      "|B003MTTJOY| 9732| 3.929613645704891|\n",
      "+----------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4: Electronics\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Electronics.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count , AVG(overall) as average_score FROM AMAZON_FASHION WHERE verified = True GROUP BY asin ORDER BY count DESC LIMIT 20\")\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"sqlDF1\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF1 LEFT JOIN viewMetaData ON sqlDF1.asin = viewMetadata.product_id ORDER BY count DESC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|      asin|count|     average_score|\n",
      "+----------+-----+------------------+\n",
      "|B00FLYWNYQ|22708| 4.599920732781398|\n",
      "|B00Q7EV29G|15206|  4.18124424569249|\n",
      "|B00EINBSJ2|14856| 4.347670974690361|\n",
      "|B009HVH4XO|14751| 4.300454206494475|\n",
      "|B000YGEVMI|14712| 4.361813485589995|\n",
      "|B00LV4W8BI|13529|  4.27710843373494|\n",
      "|B00NX47YP4|12972| 4.564754856614246|\n",
      "|B019D9HESO|11987| 4.525402519396012|\n",
      "|B0014CX87U|10848| 4.314896755162242|\n",
      "|B009ZJ2M7G|10518| 4.338467389237498|\n",
      "|B0012LOQUQ|10208| 4.161931818181818|\n",
      "|B00902X68W|10062|4.2412045319022065|\n",
      "|B0015TMHSI| 9173| 3.992041861986264|\n",
      "|B00COK3FD8| 9171| 4.558935775815069|\n",
      "|B0091YYUAM| 8942| 4.244687989264147|\n",
      "|B007WQ9YNE| 8872| 4.105838593327322|\n",
      "|B00VANO9OE| 8313| 4.346926500661614|\n",
      "|B001892AX2| 8175| 4.124892966360856|\n",
      "|B00IR77HOK| 8037| 4.254821450790096|\n",
      "|B00X8KSKF6| 7946| 4.357160835640574|\n",
      "+----------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5: Home_and_Kitchen\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Home_and_Kitchen.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count , AVG(overall) as average_score FROM AMAZON_FASHION WHERE verified = True GROUP BY asin ORDER BY count DESC LIMIT 20\")\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"sqlDF1\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF1 LEFT JOIN viewMetaData ON sqlDF1.asin = viewMetadata.product_id ORDER BY count DESC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|      asin|count|     average_score|\n",
      "+----------+-----+------------------+\n",
      "|B00V6JAEDC| 9693| 4.392138656762612|\n",
      "|B0017IHRNM| 8888| 4.579095409540954|\n",
      "|B00FO9ZRYQ| 8143| 4.328380203856073|\n",
      "|B00G7H793G| 8050|3.7783850931677017|\n",
      "|B0013092CS| 7876|4.2440325038090405|\n",
      "|B004X55L9I| 7639| 4.654666841209583|\n",
      "|B0017IFSIS| 7404| 4.565235008103728|\n",
      "|B0010O748Q| 7290|3.9982167352537723|\n",
      "|B00NPLSZF8| 7265| 4.720440467997247|\n",
      "|B00X77YTS2| 7251| 4.430699213901531|\n",
      "|B018L2WM86| 6992|  4.74899885583524|\n",
      "|B00FFADO8A| 6842| 4.455860859397837|\n",
      "|B00177BQJE| 6522|3.6931922723091075|\n",
      "|7245456313| 6144| 4.614908854166667|\n",
      "|B00A6TBITM| 6077|3.6774724370577587|\n",
      "|B0076R6MN4| 5821|   4.4095516234324|\n",
      "|B001N3MKT2| 5739| 4.724167973514549|\n",
      "|B0146A4SWA| 5737| 4.239846609726338|\n",
      "|B00SGB60YK| 5671| 4.419679068947276|\n",
      "|B00Q46Z7A2| 5670| 4.419223985890652|\n",
      "+----------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6: Sports_and_Outdoors\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Sports_and_Outdoors.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count , AVG(overall) as average_score FROM AMAZON_FASHION WHERE verified = True GROUP BY asin ORDER BY count DESC LIMIT 20\")\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"sqlDF1\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF1 LEFT JOIN viewMetaData ON sqlDF1.asin = viewMetadata.product_id ORDER BY count DESC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------------+\n",
      "|      asin|count|    average_score|\n",
      "+----------+-----+-----------------+\n",
      "|B00HTK1NCS| 5848|4.212722298221614|\n",
      "|B004RMK57U| 4972|4.525140788415125|\n",
      "|B00KKAQYXM| 3971|3.908335431881138|\n",
      "|B003ZSP0WW| 3767|4.513140430050438|\n",
      "|B00JJNQG98| 3671|4.266684827022609|\n",
      "|B00E4MQODC| 3189|4.239573534023204|\n",
      "|B000B9RI14| 3144|4.628498727735369|\n",
      "|B00DBDPOZ4| 2883|4.109608047173084|\n",
      "|B000HZFCT2| 2791|4.531350770333214|\n",
      "|B00CMN0Z0S| 2780|4.196043165467626|\n",
      "|B00178630A| 2685|3.212290502793296|\n",
      "|B00BGA9X9W| 2672|4.402320359281437|\n",
      "|B00BFOEY4I| 2670| 3.89625468164794|\n",
      "|B0015AARJI| 2626|4.051789794364052|\n",
      "|B00GU8W5AE| 2623|4.367518109035456|\n",
      "|B00AAS888S| 2578|4.228083785880528|\n",
      "|B012DFI02O| 2576|3.905667701863354|\n",
      "|B00CQ35C1Q| 2558|3.844800625488663|\n",
      "|B00BU3ZLJQ| 2545|4.624361493123772|\n",
      "|B00MYTSDU4| 2536|4.292192429022082|\n",
      "+----------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7: Video_Games\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Video_Games.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count , AVG(overall) as average_score FROM AMAZON_FASHION WHERE verified = True GROUP BY asin ORDER BY count DESC LIMIT 20\")\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"sqlDF1\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF1 LEFT JOIN viewMetaData ON sqlDF1.asin = viewMetadata.product_id ORDER BY count DESC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the average review score of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: AMAZON_FASHION\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/AMAZON_FASHION.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT AVG(overall) FROM AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     avg(overall)|\n",
      "+-----------------+\n",
      "|4.112092528511223|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2: All_Beauty\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/All_Beauty.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT AVG(overall) FROM AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     avg(overall)|\n",
      "+-----------------+\n",
      "|3.933553308546787|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3: Cell_Phones_and_Accessories\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Cell_Phones_and_Accessories.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT AVG(overall) FROM AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     avg(overall)|\n",
      "+-----------------+\n",
      "|4.073685099988554|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4: Electronics\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Electronics.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT AVG(overall) FROM AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     avg(overall)|\n",
      "+-----------------+\n",
      "|4.194893574445901|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5: Home_and_Kitchen\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Home_and_Kitchen.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count , AVG(overall) as average_score FROM AMAZON_FASHION WHERE verified = True GROUP BY asin ORDER BY count DESC LIMIT 20\")\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"sqlDF1\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF1 LEFT JOIN viewMetaData ON sqlDF1.asin = viewMetadata.product_id ORDER BY count DESC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     avg(overall)|\n",
      "+-----------------+\n",
      "|4.243398403354114|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6: Sports_and_Outdoors\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Sports_and_Outdoors.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT AVG(overall) FROM AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(overall)|\n",
      "+------------------+\n",
      "|4.0220948494727224|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7: Video_Games\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Video_Games.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT AVG(overall) FROM AMAZON_FASHION\")\n",
    "\n",
    "sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- brand: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the metadata at first\n",
    "metaDF = spark.read.json(\"hdfs://orion11:21001/parsed-meta/\")\n",
    "\n",
    "metaDF.createOrReplaceTempView(\"viewMetaData\")\n",
    "\n",
    "metaDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+------------------+\n",
      "|               title|      asin|count|     average_score|\n",
      "+--------------------+----------+-----+------------------+\n",
      "|Chellysun Women's...|B01EC05AZI|  515|2.7398058252427187|\n",
      "|Pink Queen Women'...|B00UJ6GUYA| 1004|  2.99800796812749|\n",
      "|Belly Bandit Orig...|B001T4MSU6|  527| 3.301707779886148|\n",
      "|SAYFUT Women's Bu...|B0183JQHCO| 1226|3.3556280587275693|\n",
      "|Fashion Brand 925...|B00UDF11O6|  738|3.3672086720867207|\n",
      "|Allegra K Women B...|B009PMILQE|  855| 3.433918128654971|\n",
      "|Secret Wishes Del...|B0045D7VZ0|  560|              3.45|\n",
      "|Secret Wishes Del...|B000EE1NNA|  520|3.4692307692307693|\n",
      "|Allegra K Woman B...|B00E1L9QOU|  656|3.4923780487804876|\n",
      "|Waist Trainer Cor...|B00XV52VMG|  538| 3.676579925650558|\n",
      "|Lush Moda Seamles...|B018KRRC2I|  854| 3.728337236533958|\n",
      "|Kearia Women Shor...|B019Q577XC|  735| 3.763265306122449|\n",
      "|Leg Avenue Women_...|B005MF5NE6|  546|3.8058608058608057|\n",
      "|Hanes Mens EcoSma...|B000YFSR5G| 2420|  3.81198347107438|\n",
      "|Angerella Polka V...|B00YP2TNZ2|  573| 3.825479930191972|\n",
      "|Hanes Mens EcoSma...|B000YFSR4W| 1566|3.8371647509578546|\n",
      "|Leg Avenue Women'...|B0014F8TIU|  878| 3.856492027334852|\n",
      "|HD Vision Anti-Gl...|B007F55UGW|  506|3.9209486166007905|\n",
      "|DALIX Bucket Hats...|B00DHCZVMK|  594| 3.951178451178451|\n",
      "|Havaianas Women's...|B0012DR1LU|  712| 3.973314606741573|\n",
      "+--------------------+----------+-----+------------------+\n",
      "\n",
      "+--------------------+----------+-----+------------------+\n",
      "|               title|      asin|count|     average_score|\n",
      "+--------------------+----------+-----+------------------+\n",
      "|MJ Metals Jewelry...|B00RLSCLJM| 3577| 4.826670394185071|\n",
      "|MJ Metals Jewelry...|B00G8Q7JZ4|  631| 4.812995245641838|\n",
      "|Vera Bradley Zip ...|B002Z3N1HE| 1131| 4.798408488063661|\n",
      "|New Covenant Pray...|B003WJXKTO|  783| 4.745849297573436|\n",
      "|Marino Avenue Men...|B00XT15P8E| 1790| 4.732960893854749|\n",
      "|Buyless Fashion S...|B00DP5NNHY|  785| 4.694267515923567|\n",
      "|Eyeglasses holder...|B01CDV7TNE|  607| 4.685337726523888|\n",
      "|TOFL Leather Boot...|B01AQW1XI4|  632| 4.667721518987341|\n",
      "|i play. Baby Boys...|B000PHANNM| 2401| 4.658892128279883|\n",
      "|CoolFire Solar Wa...|B00ZOWJI7A|  791|4.6561314791403285|\n",
      "|Columbia Women's ...|B00DQYPSJU|  842|4.5831353919239906|\n",
      "|Powerstep Pinnacl...|B000KPIHQ4| 4270| 4.517330210772834|\n",
      "|Powerstep Pinnacl...|B000V0IBDM| 4279| 4.515073615330684|\n",
      "|Men&rsquo;s Fashi...|B00CPRP5T2|  580| 4.503448275862069|\n",
      "|OAKI Kids Rubber ...|B00UPN42RY|  791| 4.495575221238938|\n",
      "|Saxx Vibe Modern ...|B00PSM5ENS| 1139| 4.483757682177348|\n",
      "|Calvin Klein Boy'...|B000K2PJ4K|  888|4.4324324324324325|\n",
      "|90 Degree By Refl...|B00I0VHS10| 3608| 4.428215077605321|\n",
      "| i play. Baby Sol...|B00201ER88| 2081| 4.423354156655454|\n",
      "|i play. Girls' Ba...|B000P0X15G| 1823| 4.415249588590236|\n",
      "+--------------------+----------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1: AMAZON_FASHION\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/AMAZON_FASHION.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"view1\")\n",
    "\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count, AVG(overall) as average_score FROM view1 WHERE verified = True GROUP BY asin\")\n",
    "\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"view2\")\n",
    "\n",
    "\n",
    "#products with bad reviews\n",
    "sqlDF2 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score ASC LIMIT 20\")\n",
    "\n",
    "sqlDF2.createOrReplaceTempView(\"sqlDF2\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF2 LEFT JOIN viewMetaData ON sqlDF2.asin = viewMetadata.product_id ORDER BY average_score ASC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF2.show()\n",
    "\n",
    "#products with good reviews\n",
    "sqlDF3 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score DESC LIMIT 20\")\n",
    "\n",
    "sqlDF3.createOrReplaceTempView(\"sqlDF3\")\n",
    "\n",
    "showDF2 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF3 LEFT JOIN viewMetaData ON sqlDF3.asin = viewMetadata.product_id ORDER BY average_score DESC\")\n",
    "\n",
    "showDF2.show()\n",
    "\n",
    "#sqlDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2: All_Beauty\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/All_Beauty.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"view1\")\n",
    "\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count, AVG(overall) as average_score FROM view1 WHERE verified = True GROUP BY asin\")\n",
    "\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"view2\")\n",
    "\n",
    "\n",
    "#products with bad reviews\n",
    "sqlDF2 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score ASC LIMIT 20\")\n",
    "\n",
    "sqlDF2.createOrReplaceTempView(\"sqlDF2\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF2 LEFT JOIN viewMetaData ON sqlDF2.asin = viewMetadata.product_id ORDER BY average_score ASC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF2.show()\n",
    "\n",
    "#products with good reviews\n",
    "sqlDF3 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score DESC LIMIT 20\")\n",
    "\n",
    "sqlDF3.createOrReplaceTempView(\"sqlDF3\")\n",
    "\n",
    "showDF2 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF3 LEFT JOIN viewMetaData ON sqlDF3.asin = viewMetadata.product_id ORDER BY average_score DESC\")\n",
    "\n",
    "showDF2.show()\n",
    "\n",
    "#sqlDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: Cell_Phones_and_Accessories\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Cell_Phones_and_Accessories.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"view1\")\n",
    "\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count, AVG(overall) as average_score FROM view1 WHERE verified = True GROUP BY asin\")\n",
    "\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"view2\")\n",
    "\n",
    "\n",
    "#products with bad reviews\n",
    "sqlDF2 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score ASC LIMIT 20\")\n",
    "\n",
    "sqlDF2.createOrReplaceTempView(\"sqlDF2\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF2 LEFT JOIN viewMetaData ON sqlDF2.asin = viewMetadata.product_id ORDER BY average_score ASC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF2.show()\n",
    "\n",
    "#products with good reviews\n",
    "sqlDF3 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score DESC LIMIT 20\")\n",
    "\n",
    "sqlDF3.createOrReplaceTempView(\"sqlDF3\")\n",
    "\n",
    "showDF2 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF3 LEFT JOIN viewMetaData ON sqlDF3.asin = viewMetadata.product_id ORDER BY average_score DESC\")\n",
    "\n",
    "showDF2.show()\n",
    "\n",
    "#sqlDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: Electronics\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Electronics.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"view1\")\n",
    "\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count, AVG(overall) as average_score FROM view1 WHERE verified = True GROUP BY asin\")\n",
    "\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"view2\")\n",
    "\n",
    "\n",
    "#products with bad reviews\n",
    "sqlDF2 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score ASC LIMIT 20\")\n",
    "\n",
    "sqlDF2.createOrReplaceTempView(\"sqlDF2\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF2 LEFT JOIN viewMetaData ON sqlDF2.asin = viewMetadata.product_id ORDER BY average_score ASC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF2.show()\n",
    "\n",
    "#products with good reviews\n",
    "sqlDF3 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score DESC LIMIT 20\")\n",
    "\n",
    "sqlDF3.createOrReplaceTempView(\"sqlDF3\")\n",
    "\n",
    "showDF2 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF3 LEFT JOIN viewMetaData ON sqlDF3.asin = viewMetadata.product_id ORDER BY average_score DESC\")\n",
    "\n",
    "showDF2.show()\n",
    "\n",
    "#sqlDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: Home_and_Kitchen\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Home_and_Kitchen.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"view1\")\n",
    "\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count, AVG(overall) as average_score FROM view1 WHERE verified = True GROUP BY asin\")\n",
    "\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"view2\")\n",
    "\n",
    "\n",
    "#products with bad reviews\n",
    "sqlDF2 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score ASC LIMIT 20\")\n",
    "\n",
    "sqlDF2.createOrReplaceTempView(\"sqlDF2\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF2 LEFT JOIN viewMetaData ON sqlDF2.asin = viewMetadata.product_id ORDER BY average_score ASC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF2.show()\n",
    "\n",
    "#products with good reviews\n",
    "sqlDF3 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score DESC LIMIT 20\")\n",
    "\n",
    "sqlDF3.createOrReplaceTempView(\"sqlDF3\")\n",
    "\n",
    "showDF2 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF3 LEFT JOIN viewMetaData ON sqlDF3.asin = viewMetadata.product_id ORDER BY average_score DESC\")\n",
    "\n",
    "showDF2.show()\n",
    "\n",
    "#sqlDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6: Sports_and_Outdoors\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Sports_and_Outdoors.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"view1\")\n",
    "\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count, AVG(overall) as average_score FROM view1 WHERE verified = True GROUP BY asin\")\n",
    "\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"view2\")\n",
    "\n",
    "\n",
    "#products with bad reviews\n",
    "sqlDF2 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score ASC LIMIT 20\")\n",
    "\n",
    "sqlDF2.createOrReplaceTempView(\"sqlDF2\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF2 LEFT JOIN viewMetaData ON sqlDF2.asin = viewMetadata.product_id ORDER BY average_score ASC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF2.show()\n",
    "\n",
    "#products with good reviews\n",
    "sqlDF3 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score DESC LIMIT 20\")\n",
    "\n",
    "sqlDF3.createOrReplaceTempView(\"sqlDF3\")\n",
    "\n",
    "showDF2 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF3 LEFT JOIN viewMetaData ON sqlDF3.asin = viewMetadata.product_id ORDER BY average_score DESC\")\n",
    "\n",
    "showDF2.show()\n",
    "\n",
    "#sqlDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7: Video_Games\n",
    "\n",
    "#Task: Load the raw data from HDFS, filter out the fields we don't need. Then, write back to the HDFS\n",
    "originalDF = spark.read.json(\"hdfs://orion11:21001/p4/Video_Games.json\")\n",
    "\n",
    "originalDF.createOrReplaceTempView(\"view1\")\n",
    "\n",
    "\n",
    "sqlDF1 = spark.sql(\"SELECT asin, COUNT(*) AS count, AVG(overall) as average_score FROM view1 WHERE verified = True GROUP BY asin\")\n",
    "\n",
    "\n",
    "sqlDF1.createOrReplaceTempView(\"view2\")\n",
    "\n",
    "\n",
    "#products with bad reviews\n",
    "sqlDF2 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score ASC LIMIT 20\")\n",
    "\n",
    "sqlDF2.createOrReplaceTempView(\"sqlDF2\")\n",
    "\n",
    "showDF1 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF2 LEFT JOIN viewMetaData ON sqlDF2.asin = viewMetadata.product_id ORDER BY average_score ASC\")\n",
    "\n",
    "showDF1.show()\n",
    "\n",
    "#sqlDF2.show()\n",
    "\n",
    "#products with good reviews\n",
    "sqlDF3 = spark.sql(\"SELECT asin, count, average_score FROM view2 WHERE count > 500 ORDER BY average_score DESC LIMIT 20\")\n",
    "\n",
    "sqlDF3.createOrReplaceTempView(\"sqlDF3\")\n",
    "\n",
    "showDF2 = spark.sql(\"SELECT title, asin, count, average_score FROM sqlDF3 LEFT JOIN viewMetaData ON sqlDF3.asin = viewMetadata.product_id ORDER BY average_score DESC\")\n",
    "\n",
    "showDF2.show()\n",
    "\n",
    "#sqlDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
